# =================================================================
#      SYNAPSE - ENVIRONMENT VARIABLES TEMPLATE
# =================================================================
#
# How to use this file:
# 1. Create a copy of this file in the same directory and name it ".env"
#    (e.g., run `cp .env.example .env` in the terminal)
# 2. Fill in the necessary values for the variables below.
#
# NOTE: This project is configured to run entirely locally by default,
# so no variables are strictly required to get started. The variables
# below are for optional features and extensions.

# -----------------------------------------------------------------
#  LLM Provider Configuration (Optional)
# -----------------------------------------------------------------
# Uncomment ONE of the following sections if you want to use a cloud-based
# LLM service instead of the local Ollama setup.

# --- OpenAI ---
# Provides access to models like GPT-4, GPT-3.5-turbo, etc.
# Get your key from: https://platform.openai.com/api-keys
# OPENAI_API_KEY="sk-..."


# --- Anthropic ---
# Provides access to Claude models.
# Get your key from: https://console.anthropic.com/
# ANTHROPIC_API_KEY="sk-ant-..."


# -----------------------------------------------------------------
#  Observability & Debugging with LangSmith (Optional)
# -----------------------------------------------------------------
# LangSmith is a platform for debugging, testing, and monitoring your
# LLM applications. It is highly recommended for development.
# Get your API key from: https://smith.langchain.com/

# Set to "true" to enable tracing your application runs in LangSmith
# LANGCHAIN_TRACING_V2="true"

# Your LangSmith API Key
# LANGCHAIN_API_KEY="ls__..."

# Optional: A name for your project in the LangSmith dashboard
# LANGCHAIN_PROJECT="Synapse Project"